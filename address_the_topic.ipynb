{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topical_part(prompt):\n",
    "    sentences = nltk.sent_tokenize(prompt)\n",
    "    if len(sentences) < 3:\n",
    "        return prompt  \n",
    "    topic = sentences[1]\n",
    "    return topic\n",
    "\n",
    "def get_similarity(text1, text2):\n",
    "    text1 = ' '.join([word for word in text1.split() if word.lower() not in nltk.corpus.stopwords.words('english')])\n",
    "    text2 = ' '.join([word for word in text2.split() if word.lower() not in nltk.corpus.stopwords.words('english')])\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
    "    similarity = (tfidf_matrix * tfidf_matrix.T)[0,1]\n",
    "\n",
    "    # Assign a score based on the similarity\n",
    "    if similarity < 0.1:\n",
    "        score = 1\n",
    "    elif similarity < 0.2:\n",
    "        score = 2\n",
    "    elif similarity < 0.4:\n",
    "        score = 3\n",
    "    elif similarity < 0.6:\n",
    "        score = 4\n",
    "    else:\n",
    "        score = 5\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load SpaCy's English model with word vectors\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_and_vectorize(inp_str):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(inp_str)\n",
    "\n",
    "    # Get the vector representation of each word\n",
    "    word_vectors = [nlp(word).vector for word in tokens]\n",
    "\n",
    "    return word_vectors\n",
    "\n",
    "def sent_embedding(user_input):\n",
    "    # Write your code here:\n",
    "    vectors = tokenize_and_vectorize(user_input)\n",
    "    embedding = np.zeros(len(vectors[0]), )\n",
    "    for vector in vectors:\n",
    "        embedding += vector\n",
    "    embedding /= len(vectors)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    sim = 0.0\n",
    "\n",
    "    # Copy your cosine_similarity code here\n",
    "    numerator = np.dot(a, b)\n",
    "    denominator = np.linalg.norm(a) * np.linalg.norm(b)\n",
    "    if numerator == 0:\n",
    "        return 0\n",
    "    sim = numerator / denominator\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay_embedding(essay):\n",
    "    sents = sent_tokenize(essay)\n",
    "    embedding = np.zeros(sent_embedding(sents[0]).shape)\n",
    "    for s in sents:\n",
    "        embedding += sent_embedding(s)\n",
    "    embedding /= len(sents)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('essays_dataset/index.csv', sep=';')\n",
    "df_low = df[df['grade'] == 'low']\n",
    "df_high = df[df['grade'] == 'high']\n",
    "\n",
    "df_low.reset_index(drop=True, inplace=True)\n",
    "df_high.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_similarities = []\n",
    "for index, row in df_low.iterrows():\n",
    "    prompt = get_topical_part(row['prompt'])\n",
    "    with open('essays_dataset/essays/' + row['filename'], 'r') as file:\n",
    "        essay = file.read()\n",
    "    similarity = get_similarity(prompt, essay)\n",
    "    low_similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_similarities = []\n",
    "for index, row in df_high.iterrows():\n",
    "    prompt = get_topical_part(row['prompt'])\n",
    "    with open('essays_dataset/essays/' + row['filename'], 'r') as file:\n",
    "        essay = file.read()\n",
    "    similarity = get_similarity(prompt, essay)\n",
    "    high_similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.86\n",
      "3.04\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(low_similarities))\n",
    "print(np.mean(high_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_similarities = []\n",
    "for i in range(99):\n",
    "    prompt = get_topical_part(df.loc[i+1,'prompt'])\n",
    "    with open('essays_dataset/essays/' + df.loc[i,'filename'], 'r') as file:\n",
    "        essay = file.read()\n",
    "    similarity = get_similarity(prompt, essay)\n",
    "    wrong_similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3131313131313131"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wrong_similarities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
