{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk.corpus import brown\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(tree):\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            parent = subtree.label()\n",
    "            if parent not in parent_child_grandchild:\n",
    "                parent_child_grandchild[parent] = dict()\n",
    "            for child in subtree:\n",
    "                if type(child) == nltk.tree.Tree:\n",
    "                    if child.label() not in parent_child_grandchild[parent]:\n",
    "                        parent_child_grandchild[parent][child.label()] = list()\n",
    "                    for grandchild in child:\n",
    "                        if type(grandchild) == nltk.tree.Tree:\n",
    "                            if grandchild.label() not in parent_child_grandchild[parent][child.label()]:\n",
    "                                parent_child_grandchild[parent][child.label()].append(grandchild.label())\n",
    "                            # parent_child_grandchild[parent][child.label()].add(grandchild.label())\n",
    "                        else:\n",
    "                            if grandchild[1] not in parent_child_grandchild[parent][child.label()]:\n",
    "                                parent_child_grandchild[parent][child.label()].append(grandchild[1])\n",
    "                            # parent_child_grandchild[parent][child.label()].add(grandchild[1])\n",
    "                else:\n",
    "                    child = child[1]\n",
    "                    parent_child_grandchild[parent][child] = list()\n",
    "            traverse_tree(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57340/57340 [00:32<00:00, 1752.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define your grammar\n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT>?<JJ.*>*<NN.*>+|<NNPS>+}        # Noun Phrase: optional determiner, any number of adjectives, singular or plural nouns (including proper nouns)\n",
    "        {<PRP>|<PRP$>}                       # Personal pronouns or possessive pronouns\n",
    "        {<NP><POS><NN.*>+|<NNP>+|<NNPS>+}    # Noun phrases that use possessive endings or include proper nouns (singular/plural)\n",
    "        {<EX><VB.*>}                         # Existential there constructions, e.g., \"There is\" or \"There are\"\n",
    "        {<NNP>+|<NNPS>+}                     # Proper noun sequences, potentially forming proper noun phrases (singular/plural)\n",
    "    VP: {<MD>?<VB.*>+<RB.*>*}                # Verb Phrase: optional modal, one or more verbs (including past tense), any number of adverbs\n",
    "        {<TO><VB>}                           # Infinitive verbs\n",
    "        {<VBD><RB.*>*}                       # Past tense verb followed by any number of adverbs\n",
    "        {<VBG><RB.*>*}                       # Present participle verb followed by any number of adverbs\n",
    "        {<VBP><RB.*>*}                       # Non-3rd person singular present verb followed by any number of adverbs\n",
    "        {<VBN><RB.*>*}                       # Past participle verb followed by any number of adverbs\n",
    "        {<VBZ><RB.*>*}                       # 3rd person singular present verb followed by any number of adverbs\n",
    "    ADJP: {<RB.*>*<JJ.*>+}                   # Adjective Phrase: any number of adverbs followed by one or more adjectives\n",
    "        {<JJR>|<JJS>}                        # Comparative and Superlative adjectives directly\n",
    "    ADVP: {<RB.*>+}                          # Adverb Phrase: one or more adverbs\n",
    "        {<RBR>|<RBS>}                        # Comparative and superlative adverbs\n",
    "    PP: {<IN><NP>}                           # Prepositional Phrase: preposition followed by a noun phrase\n",
    "    CONJP: {<CC>}                            # Conjunction Phrase: coordinating conjunction\n",
    "    INTJ: {<UH>}                             # Interjection\n",
    "    DP: {<DT>|<PDT>|<WDT>|<EX>}              # Determiner Phrase: determiners, pre-determiners, wh-determiners, or existential \"there\"\n",
    "    QP: {<CD><NNS|NN>?}                      # Quantifier Phrase: cardinal number followed optionally by plural or singular noun\n",
    "    WHNP: {<WP>|<WP$>|<WRB>|<WDT>}           # WH Noun Phrase: wh-pronoun, possessive wh-pronoun, wh-adverb, or wh-determiner\n",
    "    SYMP: {<SYM>}                            # Symbol Phrase: handling symbols\n",
    "    CD-NP: {<CD><JJ.*>*<NN.*>+}              # Number followed by adjectives and nouns\n",
    "    PAST-VP: {<VBD><RB.*>*}                  # Past tense verb followed by any number of adverbs\n",
    "    PRES-VP: {<VBG><RB.*>*}                  # Present participle verb followed by any number of adverbs\n",
    "    NON3RD-VP: {<VBP><RB.*>*}                # Non-3rd person singular present verb followed by any number of adverbs\n",
    "    PERFECT-VP: {<VBN><RB.*>*}               # Past participle verb followed by any number of adverbs\n",
    "    THIRD-PERSON-VP: {<VBZ><RB.*>*}          # 3rd person singular present verb followed by any number of adverbs\n",
    "    LIST-NP: {<LS><NP>+}                     # List item markers followed by Noun Phrases, e.g., in enumerated lists\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "parent_child_grandchild = {}\n",
    "\n",
    "sentences = brown.sents()\n",
    "\n",
    "# s = sentences[17]\n",
    "# # tokens = word_tokenize(s)\n",
    "# tagged_tokens = pos_tag(s)\n",
    "# tree = cp.parse(tagged_tokens)\n",
    "# tree.draw()\n",
    "# traverse_tree(tree)\n",
    "for sentence in tqdm(sentences):\n",
    "    tagged_tokens = nltk.pos_tag(sentence)\n",
    "    tree = cp.parse(tagged_tokens)\n",
<<<<<<< HEAD
    "    traverse_tree(tree)\n",
=======
    "    # tree.draw()\n",
    "    traverse_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NP': {'DT',\n",
       "  'EX',\n",
       "  'JJ',\n",
       "  'JJR',\n",
       "  'JJS',\n",
       "  'NN',\n",
       "  'NNP',\n",
       "  'NNPS',\n",
       "  'NNS',\n",
       "  'PRP',\n",
       "  'VB',\n",
       "  'VBD',\n",
       "  'VBG',\n",
       "  'VBN',\n",
       "  'VBP',\n",
       "  'VBZ'},\n",
       " 'VP': {'MD', 'RB', 'RBR', 'RBS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'},\n",
       " 'PP': {'IN', 'NP'},\n",
       " 'ADVP': {'RB', 'RBR', 'RBS'},\n",
       " 'DP': {'DT', 'EX', 'PDT', 'WDT'},\n",
       " 'CONJP': {'CC'},\n",
       " 'ADJP': {'JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS'},\n",
       " 'QP': {'CD'},\n",
       " 'WHNP': {'WP', 'WRB'},\n",
       " 'INTJ': {'UH'},\n",
       " 'SYMP': {'SYM'},\n",
       " 'LIST-NP': {'LS', 'NP'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(tree):\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            parent = subtree.label()\n",
    "            if parent not in parent_child:\n",
    "                parent_child[parent] = set()\n",
    "            for child in subtree:\n",
    "                if type(child) == nltk.tree.Tree:\n",
    "                    parent_child[parent].add(child.label())\n",
    "                else:\n",
    "                    parent_child[parent].add(child[1])\n",
    "            traverse_tree(subtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raj's Code\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def check_sentence_syntax(sentence, checker_dict):\n",
    "    mistakes = 0\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    # Get tokens from NLTK\n",
    "    tagged_tokens = pos_tag(sentence)\n",
    "    tree = cp.parse(tagged_tokens)\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == nltk.tree.Tree:\n",
    "            parent = subtree.label()\n",
    "            for child in subtree:\n",
    "                if type(child) == nltk.tree.Tree:\n",
    "                    child_label = child.label()\n",
    "                    for subsubtree in child:\n",
    "                        if type(subsubtree) == nltk.tree.Tree:\n",
    "                            subsubtree_label = subsubtree.label()        \n",
    "                            if parent in checker_dict.keys():\n",
    "                                if child_label not in checker_dict[parent].keys():\n",
    "                                    mistakes += 1 \n",
    "                                    continue\n",
    "                                else:\n",
    "                                    if subsubtree_label not in checker_dict[parent][child_label]:\n",
    "                                        mistakes += 1\n",
    "                                        continue\n",
    "                            else:\n",
    "                                mistakes += 1\n",
    "                                continue\n",
    "    return mistakes\n",
    "\n",
    "def general_scorer_gaussian_assumption(x, mean, stddev, min_score, max_score, reverse=False):\n",
    "    z_score = (x - mean) / stddev\n",
    "    z_min, z_max = -3, 3\n",
    "\n",
    "    score = (z_score - z_min) / (z_max - z_min) * (max_score - min_score) + min_score\n",
    "    if reverse:\n",
    "        score = max_score - score + min_score\n",
    "    return np.clip(score, min_score, max_score)\n",
    "\n",
    "\n",
    "mistakes_per_essay = []\n",
    "for filename in os.listdir(os.path.join(\"essays_dataset\", \"essays\")):\n",
    "    with open(os.path.join(\"essays_dataset\", \"essays\", filename)) as file:\n",
    "        text = file.read()\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        mistakes = 0\n",
    "        for sentence in sentences:\n",
    "            mistakes += check_sentence_syntax(sentence, parent_child)\n",
    "        mistakes_per_essay.append(mistakes)\n",
    "\n",
    "\n",
    "def score_essay_syntax(text, min_score, max_score):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    mistakes = 0\n",
    "    for sentence in sentences:\n",
    "        mistakes += check_sentence_syntax(sentence, parent_child)\n",
    "    mean = np.mean(mistakes_per_essay)\n",
    "    stddev = np.std(mistakes_per_essay)\n",
    "    score = general_scorer_gaussian_assumption(mistakes, mean, stddev, min_score, max_score, reverse=True)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('urged', 'VBD'), ('that', 'IN'), ('the', 'DT'), ('city', 'NN'), ('``', '``'), ('take', 'VB'), ('steps', 'NNS'), ('to', 'TO'), ('remedy', 'VB'), (\"''\", \"''\"), ('this', 'DT'), ('problem', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tagged_tokens = pos_tag(sentences[10])\n",
    "print(tagged_tokens)\n",
    "tree = cp.parse(tagged_tokens)\n",
>>>>>>> 10b057b754cf68e438dcb8756fdc993ac324a807
    "\n",
    "with open('parent_child.json', 'w') as f:\n",
    "    json.dump(parent_child_grandchild, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
